# Summary:
# Creates a new deployment on Vercel's platform, when anything is pushed in any branch (except for the "master" branch).
# Read ./README.md for extensive documentation

name: Deploy to Vercel (production)

on:
  # There are several ways to trigger Github actions - See https://help.github.com/en/actions/reference/events-that-trigger-workflows#example-using-a-single-event for a comprehensive list:
  # - "push": Triggers each time a commit is pushed
  # - "pull_request": Triggers each time a commit is pushed within a pull request, it makes it much easier to write comments within the PR, but it suffers some strong limitations:
  #   - There is no way to trigger when a PR is merged into another - See https://github.community/t/pull-request-action-does-not-run-on-merge/16092?u=vadorequest
  #   - It won't trigger when the PR is conflicting with its base branch - See https://github.community/t/run-actions-on-pull-requests-with-merge-conflicts/17104/2?u=vadorequest
  push: # Triggers on each pushed commit
    branches:
      - 'master'

  # Allow manual trigger via a button in github or a HTTP call - See https://docs.github.com/en/actions/configuring-and-managing-workflows/configuring-a-workflow#manually-running-a-workflow
  # XXX Read more about how to use it with NRN in .github/WORKFLOW_DISPATCH.md
  workflow_dispatch:
    inputs:
      customer:
        description: 'Customer to deploy'
        required: true

jobs:
  # Configures the deployment environment, install dependencies (like node, npm, etc.) that are requirements for the upcoming jobs
  # Ex: Necessary to run `yarn deploy`
  setup-environment:
    name: Setup deployment environment (Ubuntu 18.04 - Node 12.x)
    runs-on: ubuntu-18.04
    steps:
      - name: Installing node.js
        uses: actions/setup-node@v1 # Used to install node environment - XXX https://github.com/actions/setup-node
        with:
          node-version: '12.x' # Use the same node.js version as the one Vercel's uses (currently node12.x)

  # Starts a Vercel deployment, using the production configuration file of the default institution
  # The default institution is the one defined in the `vercel.json` file (which is a symlink to the actual file)
  # N.B: It's Vercel that will perform the actual deployment
  start-production-deployment:
    name: Starts Vercel deployment (production) (Ubuntu 18.04)
    runs-on: ubuntu-18.04
    needs: setup-environment
    steps:
      - uses: actions/checkout@v1 # Get last commit pushed - XXX See https://github.com/actions/checkout
      - name: Deploying on Vercel (production)
        # Workflow overview:
        #   - Resolve customer to deploy from github event input (falls back to resolving it from vercel.json file)
        #   - Deploy the customer in production
        # XXX You can use https://jqplay.org/ if you want to play around with "jq" to manipulate JSON
        run: |
          # Print the version of the "vercel" CLI being used (helps debugging)
          vercel --version
          echo "Deploying using git commit SHA: $GIT_COMMIT_SHA and branch/tag: $GIT_COMMIT_REF"

          # Resolving customer to deploy based on the github event input, when using manual deployment triggerer through "workflow_dispatch" event
          # Falls back to the customer specified in the vercel.json file, which is most useful when deployment is triggered through "push" event
          MANUAL_TRIGGER_CUSTOMER="${{ github.event.inputs.customer}}"
          echo "MANUAL_TRIGGER_CUSTOMER: " $MANUAL_TRIGGER_CUSTOMER
          echo "MANUAL_TRIGGER_CUSTOMER=$MANUAL_TRIGGER_CUSTOMER" >> $GITHUB_ENV

          CUSTOMER_REF_TO_DEPLOY="${MANUAL_TRIGGER_CUSTOMER:-$(cat vercel.json | jq --raw-output '.build.env.NEXT_PUBLIC_CUSTOMER_REF')}"
          echo "Customer to deploy: " $CUSTOMER_REF_TO_DEPLOY

          # Deploy the customer on Vercel using the customer specified in vercel.json
          CUSTOMER_REF=${CUSTOMER_REF_TO_DEPLOY} yarn deploy:customer:production:simple --token $VERCEL_TOKEN

          # Find all custom aliases configured in the customer deployment configuration file (vercel.json)
          VERCEL_DEPLOYMENT_ALIASES_JSON=$(cat vercel.$CUSTOMER_REF_TO_DEPLOY.production.json | jq --raw-output '.alias')
          echo "Custom aliases: " $VERCEL_DEPLOYMENT_ALIASES_JSON

          # Convert the JSON array into a bash array - See https://unix.stackexchange.com/a/615717/60329
          readarray -t VERCEL_DEPLOYMENT_ALIASES < <(jq --raw-output '.alias[]' < vercel.$CUSTOMER_REF_TO_DEPLOY.production.json)

          # Count the number of element in the array, will be 0 if it's an empty array, or if the "alias" key wasn't defined
          VERCEL_DEPLOYMENT_ALIASES_COUNT=${#VERCEL_DEPLOYMENT_ALIASES[@]}

          # Check if there are no aliases configured
          if [ "$VERCEL_DEPLOYMENT_ALIASES" > 0 ]
          then
            echo "$VERCEL_DEPLOYMENT_ALIASES_COUNT alias(es) found. Aliasing them now..."

            # For each alias configured, then assign it to the deployed domain
            for DEPLOYMENT_ALIAS in "${VERCEL_DEPLOYMENT_ALIASES[@]}"; do
              echo "npx vercel alias "$VERCEL_DEPLOYMENT_URL $DEPLOYMENT_ALIAS
              npx vercel alias $VERCEL_DEPLOYMENT_URL $DEPLOYMENT_ALIAS --token $VERCEL_TOKEN || echo "Aliasing failed for '$DEPLOYMENT_ALIAS', but the build will continue regardless."
            done
          else
            # $VERCEL_DEPLOYMENT_ALIASES is null, this happens when it was not defined in the vercel.json file
            echo "There are no more aliases to configure. You can add more aliases from your vercel.json 'alias' property. See https://vercel.com/docs/configuration?query=alias%20domain#project/alias"
            echo "$VERCEL_DEPLOYMENT_ALIASES"
          fi
        env:
          VERCEL_TOKEN: ${{ secrets.VERCEL_TOKEN }} # Passing github's secret to the worker
          GIT_COMMIT_REF: ${{ github.ref }} # Passing current branch/tag to the worker
          GIT_COMMIT_SHA: ${{ github.sha }} # Passing current commit SHA to the worker

  await-for-vercel-deployment:
    name: Await current deployment to be ready (Ubuntu 18.04)
    runs-on: ubuntu-18.04
    needs: start-production-deployment
    steps:
      - name: Resolving deployment url from Vercel
        # Workflow overview:
        #   - Resolve customer to deploy from github event input (falls back to resolving it from vercel.json file)
        #   - Resolve $VERCEL_DEPLOYMENT_URL
        #     - Fetch all deployments data (by using the scope in `vercel.json`)
        #     - Resolve the last url (from `response.deployments[0].url`)
        #     - Remove the `"` character to pre-format url
        # We need to set env the url for next step, formatted as `https://${$VERCEL_DEPLOYMENT}`
        # XXX You can use https://jqplay.org/ if you want to play around with "jq" to manipulate JSON
        run: |
          apt update -y >/dev/null && apt install -y jq >/dev/null

          MANUAL_TRIGGER_CUSTOMER="${{ github.event.inputs.customer}}"
          echo "MANUAL_TRIGGER_CUSTOMER: " $MANUAL_TRIGGER_CUSTOMER
          echo "MANUAL_TRIGGER_CUSTOMER=$MANUAL_TRIGGER_CUSTOMER" >> $GITHUB_ENV

          CUSTOMER_REF_TO_DEPLOY="${MANUAL_TRIGGER_CUSTOMER:-$(cat vercel.json | jq --raw-output '.build.env.NEXT_PUBLIC_CUSTOMER_REF')}"
          echo "Customer that was deployed: " $CUSTOMER_REF_TO_DEPLOY
          echo "CUSTOMER_REF_TO_DEPLOY=$CUSTOMER_REF_TO_DEPLOY" >> $GITHUB_ENV

          # Resolve Vercel team ID
          VERCEL_TEAM_ID=`cat vercel.$CUSTOMER_REF_TO_DEPLOY.production.json | jq --raw-output '.scope'`
          echo "Vercel team ID: " $VERCEL_TEAM_ID
          echo "VERCEL_TEAM_ID=$VERCEL_TEAM_ID" >> $GITHUB_ENV

          # Resolve Vercel project name
          VERCEL_PROJECT_NAME=`cat vercel.$CUSTOMER_REF_TO_DEPLOY.production.json | jq --raw-output '.name'`
          echo "Vercel project name: " $VERCEL_PROJECT_NAME
          echo "VERCEL_PROJECT_NAME=$VERCEL_PROJECT_NAME" >> $GITHUB_ENV

          # Build Vercel API endpoint used to fetch deployments
          VERCEL_FETCH_DEPLOYMENTS_API_ENDPOINT="https://api.zeit.co/v5/now/deployments?teamId=$VERCEL_TEAM_ID"
          echo "Fetching Vercel deployments using API endpoint: " $VERCEL_FETCH_DEPLOYMENTS_API_ENDPOINT

          # Fetch all Vercel deployment from this project
          ALL_VERCEL_DEPLOYMENTS=`curl -H 'Accept: application/json' -H 'Content-Type: application/json' -H 'Authorization: Bearer ${{ secrets.VERCEL_TOKEN }}' $VERCEL_FETCH_DEPLOYMENTS_API_ENDPOINT`
          echo "Vercel deployments for current team: " $ALL_VERCEL_DEPLOYMENTS

          # Parse the deployments (as json) to find the latest deployment url, while stripping the double quotes
          # TODO Do not use '.deployments [0].url' blindly, but filter the deployments array first to make sure to consider only the deployments where "name" is equal to $VERCEL_PROJECT_NAME
          VERCEL_DEPLOYMENT=`echo $ALL_VERCEL_DEPLOYMENTS | jq '.deployments [0].url' | tr -d \"`
          VERCEL_DEPLOYMENT_URL="https://$VERCEL_DEPLOYMENT"
          echo "Url where to run E2E tests (VERCEL_DEPLOYMENT_URL): " $VERCEL_DEPLOYMENT_URL
          echo "VERCEL_DEPLOYMENT_URL=$VERCEL_DEPLOYMENT_URL" >> $GITHUB_ENV
          echo "VERCEL_DEPLOYMENT=$VERCEL_DEPLOYMENT" >> $GITHUB_ENV

      # Wait for deployment to be ready, before running E2E (otherwise Cypress might start testing too early, and gets redirected to Vercel's "Login page", and tests fail)
      - name: Awaiting Vercel deployment to be ready
        uses: UnlyEd/github-action-await-vercel@v1.1.1
        id: await-vercel
        env:
          VERCEL_TOKEN: ${{ secrets.VERCEl_TOKEN }}
        with:
          deployment-url: ${{ env.VERCEL_DEPLOYMENT }} # Must only contain the domain name (no http prefix, etc.)
          timeout: 90 # Wait for 90 seconds before failing

      - name: Display deployment status
        run: "echo My deployment is ${{ fromJson(steps.await-vercel.outputs.deploymentDetails).readyState }}"

  # Runs E2E tests against the Vercel deployment
  run-2e2-tests:
    name: Run end to end (E2E) tests (Ubuntu 18.04)
    runs-on: ubuntu-18.04
    # Docker image with Cypress pre-installed
    # https://github.com/cypress-io/cypress-docker-images/tree/master/included
    container: cypress/included:3.8.3
    needs: await-for-vercel-deployment
    steps:
      - uses: actions/checkout@v1 # Get last commit pushed - XXX See https://github.com/actions/checkout
      - name: Resolving deployment url from Vercel
        run: |
          apt update -y >/dev/null && apt install -y jq >/dev/null

          MANUAL_TRIGGER_CUSTOMER="${{ github.event.inputs.customer}}"
          echo "MANUAL_TRIGGER_CUSTOMER: " $MANUAL_TRIGGER_CUSTOMER
          echo "MANUAL_TRIGGER_CUSTOMER=$MANUAL_TRIGGER_CUSTOMER" >> $GITHUB_ENV

          CUSTOMER_REF_TO_DEPLOY="${MANUAL_TRIGGER_CUSTOMER:-$(cat vercel.json | jq --raw-output '.build.env.NEXT_PUBLIC_CUSTOMER_REF')}"
          echo "Customer that was deployed: " $CUSTOMER_REF_TO_DEPLOY
          echo "CUSTOMER_REF_TO_DEPLOY=$CUSTOMER_REF_TO_DEPLOY" >> $GITHUB_ENV

          # Resolve Vercel team ID
          VERCEL_TEAM_ID=`cat vercel.$CUSTOMER_REF_TO_DEPLOY.production.json | jq --raw-output '.scope'`
          echo "Vercel team ID: " $VERCEL_TEAM_ID
          echo "VERCEL_TEAM_ID=$VERCEL_TEAM_ID" >> $GITHUB_ENV

          # Resolve Vercel project name
          VERCEL_PROJECT_NAME=`cat vercel.$CUSTOMER_REF_TO_DEPLOY.production.json | jq --raw-output '.name'`
          echo "Vercel project name: " $VERCEL_PROJECT_NAME
          echo "VERCEL_PROJECT_NAME=$VERCEL_PROJECT_NAME" >> $GITHUB_ENV

          # Build Vercel API endpoint used to fetch deployments
          VERCEL_FETCH_DEPLOYMENTS_API_ENDPOINT="https://api.zeit.co/v5/now/deployments?teamId=$VERCEL_TEAM_ID"
          echo "Fetching Vercel deployments using API endpoint: " $VERCEL_FETCH_DEPLOYMENTS_API_ENDPOINT

          # Fetch all Vercel deployment from this project
          ALL_VERCEL_DEPLOYMENTS=`curl -H 'Accept: application/json' -H 'Content-Type: application/json' -H 'Authorization: Bearer ${{ secrets.VERCEL_TOKEN }}' $VERCEL_FETCH_DEPLOYMENTS_API_ENDPOINT`
          echo "Vercel deployments for current team: " $ALL_VERCEL_DEPLOYMENTS

          # Parse the deployments (as json) to find the latest deployment url, while stripping the double quotes
          # TODO Do not use '.deployments [0].url' blindly, but filter the deployments array first to make sure to consider only the deployments where "name" is equal to $VERCEL_PROJECT_NAME
          VERCEL_DEPLOYMENT=`echo $ALL_VERCEL_DEPLOYMENTS | jq '.deployments [0].url' | tr -d \"`
          VERCEL_DEPLOYMENT_URL="https://$VERCEL_DEPLOYMENT"
          echo "Url where to run E2E tests (VERCEL_DEPLOYMENT_URL): " $VERCEL_DEPLOYMENT_URL
          echo "VERCEL_DEPLOYMENT_URL=$VERCEL_DEPLOYMENT_URL" >> $GITHUB_ENV

      # Run the E2E tests against the new Vercel deployment
      - name: Run E2E tests (Cypress)
        uses: cypress-io/github-action@v2 # XXX See https://github.com/cypress-io/github-action
        with:
          wait-on: ${{ env.VERCEL_DEPLOYMENT_URL }} # Be sure that the endpoint is ready by pinging it before starting tests, it has a timeout of 60seconds
          config-file: cypress/config-customer-ci-cd.json # The config file itself doesn't matter because we will override most settings anyway. We just need `projectId` to run the tests.
          config: baseUrl=${{ env.VERCEL_DEPLOYMENT_URL }} # Overriding baseUrl provided by config file to test the new deployment
        env:
          # Enables Cypress debugging logs, very useful if Cypress crashes, like out-of-memory issues.
          #          DEBUG: "cypress:*" # Enable all logs. See https://docs.cypress.io/guides/references/troubleshooting.html#Print-DEBUG-logs
          DEBUG: "cypress:server:util:process_profiler" # Enable logs for "memory and CPU usage". See https://docs.cypress.io/guides/references/troubleshooting.html#Log-memory-and-CPU-usage

      # On E2E failure, upload screenshots
      - name: Upload screenshots artifacts (E2E failure)
        uses: actions/upload-artifact@v1 # On failure we upload artifacts, https://help.github.com/en/actions/automating-your-workflow-with-github-actions/persisting-workflow-data-using-artifacts
        if: failure()
        with:
          name: screenshots
          path: cypress/screenshots/

      # On E2E failure, upload videos
      - name: Upload videos artifacts (E2E failure)
        uses: actions/upload-artifact@v1 # On failure we upload artifacts, https://help.github.com/en/actions/automating-your-workflow-with-github-actions/persisting-workflow-data-using-artifacts
        if: failure()
        with:
          name: videos
          path: cypress/videos/

  # Run Lighthouse reports in parallel of E2E tests
  run-lighthouse-tests:
    name: Run LightHouse checks (Ubuntu 18.04)
    runs-on: ubuntu-18.04
    needs: await-for-vercel-deployment
    steps:
      - uses: actions/checkout@v1 # Get last commit pushed - XXX See https://github.com/actions/checkout
      - name: Resolving deployment url from Vercel
        # Workflow overview:
        #   - Resolve customer to deploy from github event input (falls back to resolving it from vercel.json file)
        #   - Resolve $VERCEL_DEPLOYMENT_URL
        #     - Fetch all deployments data (by using the scope in `vercel.json`)
        #     - Resolve the last url (from `response.deployments[0].url`)
        #     - Remove the `"` character to pre-format url
        # We need to set env the url for next step, formatted as `https://${$VERCEL_DEPLOYMENT}/en` using /en endpoint to improve perfs by avoiding the url redirect on /
        # XXX You can use https://jqplay.org/ if you want to play around with "jq" to manipulate JSON
        run: |
          apt update -y >/dev/null && apt install -y jq >/dev/null

          MANUAL_TRIGGER_CUSTOMER="${{ github.event.inputs.customer}}"
          echo "MANUAL_TRIGGER_CUSTOMER: " $MANUAL_TRIGGER_CUSTOMER
          echo "MANUAL_TRIGGER_CUSTOMER=$MANUAL_TRIGGER_CUSTOMER" >> $GITHUB_ENV

          CUSTOMER_REF_TO_DEPLOY="${MANUAL_TRIGGER_CUSTOMER:-$(cat vercel.json | jq --raw-output '.build.env.NEXT_PUBLIC_CUSTOMER_REF')}"
          echo "Customer that was deployed: " $CUSTOMER_REF_TO_DEPLOY
          echo "CUSTOMER_REF_TO_DEPLOY=$CUSTOMER_REF_TO_DEPLOY" >> $GITHUB_ENV

          # Resolve Vercel team ID
          VERCEL_TEAM_ID=`cat vercel.$CUSTOMER_REF_TO_DEPLOY.production.json | jq --raw-output '.scope'`
          echo "Vercel team ID: " $VERCEL_TEAM_ID
          echo "VERCEL_TEAM_ID=$VERCEL_TEAM_ID" >> $GITHUB_ENV

          # Resolve Vercel project name
          VERCEL_PROJECT_NAME=`cat vercel.$CUSTOMER_REF_TO_DEPLOY.production.json | jq --raw-output '.name'`
          echo "Vercel project name: " $VERCEL_PROJECT_NAME
          echo "VERCEL_PROJECT_NAME=$VERCEL_PROJECT_NAME" >> $GITHUB_ENV

          # Build Vercel API endpoint used to fetch deployments
          VERCEL_FETCH_DEPLOYMENTS_API_ENDPOINT="https://api.zeit.co/v5/now/deployments?teamId=$VERCEL_TEAM_ID"
          echo "Fetching Vercel deployments using API endpoint: " $VERCEL_FETCH_DEPLOYMENTS_API_ENDPOINT

          # Fetch all Vercel deployment from this project
          ALL_VERCEL_DEPLOYMENTS=`curl -H 'Accept: application/json' -H 'Content-Type: application/json' -H 'Authorization: Bearer ${{ secrets.VERCEL_TOKEN }}' $VERCEL_FETCH_DEPLOYMENTS_API_ENDPOINT`
          echo "Vercel deployments for current team: " $ALL_VERCEL_DEPLOYMENTS

          # Parse the deployments (as json) to find the latest deployment url, while stripping the double quotes
          # TODO Do not use '.deployments [0].url' blindly, but filter the deployments array first to make sure to consider only the deployments where "name" is equal to $VERCEL_PROJECT_NAME
          VERCEL_DEPLOYMENT=`echo $ALL_VERCEL_DEPLOYMENTS | jq '.deployments [0].url' | tr -d \"`
          VERCEL_DEPLOYMENT_URL="https://$VERCEL_DEPLOYMENT"
          echo "Url where to run LightHouse tests (VERCEL_DEPLOYMENT_URL): " $VERCEL_DEPLOYMENT_URL
          echo "VERCEL_DEPLOYMENT_URL=$VERCEL_DEPLOYMENT_URL" >> $GITHUB_ENV
        env:
          VERCEL_TOKEN: ${{ secrets.VERCEL_TOKEN }} # Passing github's secret to the worker
      # In order to store reports and then upload it, we need to create the folder before any tests
      - name: Create temporary folder for artifacts storage
        run: mkdir /tmp/lighthouse-artifacts

      # It runs the lighthouse report for a provided url and create a HTML report in the specified directory
      # Action documentation: https://github.com/marketplace/actions/lighthouse-check#usage-standard-example
      - name: Run Lighthouse
        uses: foo-software/lighthouse-check-action@v2.0.5
        id: lighthouseCheck
        with: # See https://github.com/marketplace/actions/lighthouse-check#inputs for all options
          # XXX We don't enable comments, because there is no branch to write them into
          outputDirectory: /tmp/lighthouse-artifacts # Used to upload artifacts.
          emulatedFormFactor: all # Run LightHouse against "mobile", "desktop", or "all" devices
          urls: ${{ env.VERCEL_DEPLOYMENT_URL }}, ${{ env.VERCEL_DEPLOYMENT_URL }}/en, ${{ env.VERCEL_DEPLOYMENT_URL }}/fr, ${{ env.VERCEL_DEPLOYMENT_URL }}/en-US, ${{ env.VERCEL_DEPLOYMENT_URL }}/fr-FR
          locale: en

      # Upload HTML report create by lighthouse, could be useful
      - name: Upload artifacts
        uses: actions/upload-artifact@v1
        with:
          name: Lighthouse reports
          path: /tmp/lighthouse-artifacts

      # Using a pre-build action to make the action fail if your score is too low. It can be really interesting to track a low score on a commit
      # You can remove this action IF you don't want lighthouse to be a blocking point in your CI
      # Official documentation: https://github.com/foo-software/lighthouse-check-status-action
      - name: Handle Lighthouse Check results
        uses: foo-software/lighthouse-check-status-action@v1.0.1
        with:
          lighthouseCheckResults: ${{ steps.lighthouseCheck.outputs.lighthouseCheckResults }}
          minAccessibilityScore: "50"
          minBestPracticesScore: "50"
          minPerformanceScore: "30"
          minProgressiveWebAppScore: "50"
          minSeoScore: "50"
